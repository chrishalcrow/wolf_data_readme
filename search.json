[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experiment summary",
    "section": "",
    "text": "This experiment is designed to find out stuff about memory.\n\n\nEach day, each mouse participated in one or more sessions. E.g. in the most common day, a mouse partakes in a single VR session."
  },
  {
    "objectID": "index.html#session-types",
    "href": "index.html#session-types",
    "title": "Experiment summary",
    "section": "",
    "text": "Each day, each mouse participated in one or more sessions. E.g. in the most common day, a mouse partakes in a single VR session."
  },
  {
    "objectID": "index.html#data-overview",
    "href": "index.html#data-overview",
    "title": "Experiment summary",
    "section": "Data overview",
    "text": "Data overview\nOur basic pipeline overview can be found below.\n\n\n\nPipeline overview\n\n\nEvery session contains an output from Bonsai or Blender, and a Video. These capture the animal behaviour data, as well as a light pulse signal used for synchronisation. Most sessions include ephys data, which capture neural behaviour.\nWe expect the most useful data to be the outputs for analysis (in teal), or the raw data (in red)."
  },
  {
    "objectID": "index.html#the-pipeline",
    "href": "index.html#the-pipeline",
    "title": "Experiment summary",
    "section": "The pipeline",
    "text": "The pipeline\n\nData structure\nThe raw data is organised as follows:\nraw/\n    session_folder/\n        M{mouse}_D{day}_datetime_{session_name}/\n            M{mouse}_D{day}_{session_name}_{datetime}.log # ??\n            M{mouse}_D{day}_{session_name}_{video_name}.avi  # video of behaviour\n            M{mouse}_D{day}_{session_name}_{video_name}.csv # behavioural output from Bonsai/Blender\n            Record Node 109/  # Ephys data\nThe processed data is organised as follows:\nprocessed/\n    M{mouse}/\n        D{day}/\n            {session_name}/\n                sub-{mouse}_day-{day}_ses-{session_name}_srt-{sorter_protocol}_analyzer.zarr # a spikeinterface SortingAnalyzer\n                sub-{mouse}_day-{day}_ses-{session_name}_srt-{sorter_protocol}_{curation_protocol}.json # a file detailing the curation of the units (e.g. are they good units? Possible merges etc)\n                sub-{mouse}_day-{day}_ses-{session_name}_beh.nwb # an nwb file containing the behavioural outputs\nThe sorting output depends on a sorting_protocol, e.g. kilosort4A. The protocols are specified in github:chrishalcrow/nolanlab-ephys/src/nolanlab_ephys/si_protocols.py.\n\n\nRunning the pipeline\nThe basic pipeline contains three scripts. We’ll go through how to run these on the Edinburgh EDDIE compute cluster here.\n\nSorting\nInstall chrishalcrow/nolanlab-ephys following the instructions here: https://github.com/chrishalcrow/nolanlab-ephys .\nFor a sorting, you need to specify a mouse, a day, the sessions you want to sort and the sorting protocol to use. You also need to point to your raw data folder and your derivatives folder. To run a sorting, you would run a command such as the one below from the nolanlab-ephys directory:\nuv run scripts/wolf/sort_on_eddie.py 4 8 MMNAV1 kilosort4A --data_folder /exports/eddie/scratch/chalcrow/wolf/data/ --deriv_folder /exports/eddie/scratch/chalcrow/wolf/derivatives\nThe exact same arguments can be used locally with a different script:\nuv run scripts/wolf/sort_on_comp.py 4 8 MMNAV1 kilosort4A --data_folder /exports/eddie/scratch/chalcrow/wolf/data/ --deriv_folder /exports/eddie/scratch/chalcrow/wolf/derivatives\n\n\nDeepLabCut\nInstall chrishalcrow/nolanlab-dlc following the instructions here: https://github.com/chrishalcrow/nolanlab-dlc .\nFor a deeplabcut run, you need to stage the DLC model used to the EDDIE, then change its path in the config.yaml file. This is annoying. The models can be found in DATASTORE/ActiveProjects/Harry/deeplabcut/.\nYou need to specify a mouse, a day, a session and a bodypart. A typical command looks like:\nuv run dlc_on_eddie.py 4 8 MMNAV1 tongue --data_folder /exports/eddie/scratch/chalcrow/wolf/data/ --deriv_folder /exports/eddie/scratch/chalcrow/wolf/derivatives\nDLC will be much more efficient if you specify a region of interest. These are stored in e.g. nolanlab-dlc/wolf_crops/tongue_crops_wolf.csv.\nYou can also run things locally using e.g.\nuv run dlc_on_comp.py 4 8 MMNAV1 tongue --data_folder /exports/eddie/scratch/chalcrow/wolf/data/ --deriv_folder /exports/eddie/scratch/chalcrow/wolf/derivatives\n\n\nSync and preprocess\nThe syncing and preprocessing of data is done using https://github.com/wulfdewolf/mmnav . Install this and follow the instructions about environments.\nYou need to specify a mouse, a day and sorter protocol. The sessions are determined automatically. If the day has no ephys, don’t include a sorting protocol. A typical command looks like:\nUV_PROJECT_ENVIRONMENT=$MMNAV_ENV uv run --no-sync --link-mode=copy --cache-dir $STORAGE/code/uv_cache/ scripts/preprocessing/HPC/queue_days.py --storage $STORAGE --sub 4 --day 15 --srt kilosort4A\n\n\n\nAccessing the data"
  }
]